<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Unit 4: Computer Vision Fundamentals - Study Guide</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: #333;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            background: white;
            padding: 30px;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.3);
        }

        h1 {
            text-align: center;
            color: #2c3e50;
            font-size: 2.5em;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.1);
        }

        .subtitle {
            text-align: center;
            color: #7f8c8d;
            font-size: 1.2em;
            margin-bottom: 30px;
        }

        h2 {
            background: linear-gradient(90deg, #e67e22, #d35400);
            color: white;
            padding: 15px;
            border-radius: 8px;
            margin: 30px 0 20px 0;
            font-size: 1.4em;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        h3 {
            color: #2c3e50;
            border-left: 4px solid #e67e22;
            padding-left: 15px;
            margin: 25px 0 15px 0;
            font-size: 1.2em;
        }

        .key-points {
            background: #ecf0f1;
            border-left: 5px solid #3498db;
            padding: 15px;
            margin: 15px 0;
            border-radius: 5px;
        }

        .exam-focus {
            background: #fff3cd;
            border: 2px solid #ffc107;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }

        .exam-focus h4 {
            color: #856404;
            margin-top: 0;
            font-size: 1.1em;
        }

        .critical-exam {
            background: #f8d7da;
            border: 2px solid #dc3545;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }

        .critical-exam h4 {
            color: #721c24;
            margin-top: 0;
            font-size: 1.1em;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        table th {
            background: linear-gradient(90deg, #2c3e50, #34495e);
            color: white;
            padding: 15px;
            text-align: left;
            font-weight: bold;
        }

        table td {
            padding: 12px 15px;
            border-bottom: 1px solid #ddd;
        }

        table tr:nth-child(even) {
            background-color: #f8f9fa;
        }

        table tr:hover {
            background-color: #e8f4f8;
        }

        .cv-category {
            background: linear-gradient(90deg, #8e44ad, #9b59b6);
            color: white;
            padding: 10px 15px;
            border-radius: 5px;
            margin: 10px 0;
            font-weight: bold;
        }

        .step-box {
            background: #e8f8f5;
            border: 1px solid #1abc9c;
            border-radius: 8px;
            padding: 15px;
            margin: 10px 0;
        }

        .pixel-demo {
            background: #f0f4ff;
            border: 2px solid #3498db;
            border-radius: 8px;
            padding: 20px;
            margin: 20px 0;
            text-align: center;
        }

        .analogy {
            background: #fdf2e9;
            border-left: 4px solid #f39c12;
            padding: 15px;
            margin: 15px 0;
            border-radius: 5px;
            font-style: italic;
        }

        .comparison {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin: 20px 0;
        }

        .vs-left,
        .vs-right {
            padding: 15px;
            border-radius: 8px;
        }

        .vs-left {
            background: #ffebee;
            border: 2px solid #e91e63;
        }

        .vs-right {
            background: #e8f5e8;
            border: 2px solid #4caf50;
        }

        .highlight {
            background: yellow;
            padding: 2px 4px;
            border-radius: 3px;
            font-weight: bold;
        }

        .filter-demo {
            background: linear-gradient(135deg, #ff9a9e 0%, #fecfef 100%);
            padding: 20px;
            border-radius: 10px;
            text-align: center;
            margin: 20px 0;
            border: 2px solid #e91e63;
        }

        .section-divider {
            height: 3px;
            background: linear-gradient(90deg, #e67e22, #d35400);
            margin: 40px 0;
            border-radius: 2px;
        }

        .challenges-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 15px;
            margin: 20px 0;
        }

        .challenge-item {
            background: #fff3cd;
            border: 2px solid #ffc107;
            padding: 15px;
            border-radius: 8px;
        }

        .feature-type {
            background: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 15px;
            margin: 15px 0;
        }

        .feature-type h4 {
            color: #495057;
            margin-top: 0;
            border-bottom: 2px solid #6c757d;
            padding-bottom: 10px;
        }

        .kernel-visual {
            background: #e3f2fd;
            border: 1px solid #2196f3;
            border-radius: 8px;
            padding: 20px;
            margin: 15px 0;
            text-align: center;
        }

        ul,
        ol {
            padding-left: 20px;
        }

        li {
            margin: 8px 0;
        }

        .emoji {
            font-size: 1.2em;
            margin-right: 8px;
        }

        .calibration-box {
            background: #d1ecf1;
            border: 1px solid #bee5eb;
            border-radius: 8px;
            padding: 15px;
            margin: 10px 0;
        }

        .matrix-demo {
            font-family: 'Courier New', monospace;
            background: #f8f9fa;
            border: 1px solid #dee2e6;
            padding: 15px;
            margin: 10px 0;
            border-radius: 5px;
            text-align: center;
        }

        @media print {
            body {
                background: white;
            }

            .container {
                box-shadow: none;
                padding: 20px;
            }
        }
    </style>
</head>

<body>
    <div class="container">
        <h1>üëÅÔ∏è UNIT 4: COMPUTER VISION FUNDAMENTALS</h1>
        <div class="subtitle">Digital Image Processing &amp; Feature Detection</div>

        <h2>üéØ KEY LEARNING GOALS</h2>
        <div class="key-points">
            <ul>
                <li><span class="emoji">üì±</span><strong>Define</strong> computer vision and its core principles</li>
                <li><span class="emoji">üî≤</span><strong>Explain</strong> how to represent images as pixel arrays</li>
                <li><span class="emoji">üîç</span><strong>Distinguish</strong> between detection, description, and
                    matching of features</li>
                <li><span class="emoji">üìê</span><strong>Correct</strong> distortion with calibration methods</li>
                <li><span class="emoji">üåü</span><strong>Apply</strong> filters for edge detection, corner detection,
                    and blob detection</li>
            </ul>
        </div>

        <div class="pixel-demo">
            <h3>üí° CORE CONCEPT</h3>
            <p><strong>Computer Vision = Teaching computers to "see" and understand visual information</strong></p>
            <p>Just like humans process visual information, AI systems analyze digital images as numerical data!</p>
        </div>

        <h2>üñºÔ∏è WHAT IS COMPUTER VISION?</h2>

        <div class="critical-exam">
            <h4>üö® EXAM CRITICAL: Computer Vision Definition</h4>
            <p>Be able to define computer vision and explain how it differs from simple image processing!</p>
        </div>

        <h3>üìä Four Major Categories of Computer Vision</h3>

        <table>
            <tbody>
                <tr>
                    <th>Category</th>
                    <th>Purpose</th>
                    <th>Key Tasks</th>
                    <th>Real-World Examples</th>
                </tr>
                <tr>
                    <td><strong>Recognition Tasks</strong></td>
                    <td>Identify and classify visual elements</td>
                    <td>Object detection, person detection, pose detection</td>
                    <td>Face recognition, autonomous driving, medical imaging</td>
                </tr>
                <tr>
                    <td><strong>Motion Analysis</strong></td>
                    <td>Track movement and changes over time</td>
                    <td>Motion tracking, activity recognition</td>
                    <td>Sports analysis, surveillance, gesture control</td>
                </tr>
                <tr>
                    <td><strong>Image Restoration</strong></td>
                    <td>Improve image quality and remove noise</td>
                    <td>Denoising, super-resolution, inpainting</td>
                    <td>Photo enhancement, satellite imagery, medical scans</td>
                </tr>
                <tr>
                    <td><strong>Geometry Reconstruction</strong></td>
                    <td>Create 3D understanding from 2D images</td>
                    <td>Depth estimation, 3D modeling, stereo vision</td>
                    <td>AR/VR, robotics, 3D mapping</td>
                </tr>
            </tbody>
        </table>

        <h3>‚ö†Ô∏è Five Major Challenges in Computer Vision</h3>

        <div class="challenges-grid">
            <div class="challenge-item">
                <h4>üí° Illumination Changes</h4>
                <p><strong>Problem:</strong> Same object looks different under different lighting</p>
                <p><strong>Example:</strong> Red appears orange in bright light</p>
                <p><strong>Solution:</strong> Normalization and robust feature detection</p>
            </div>
            <div class="challenge-item">
                <h4>üîÑ Similar Object Confusion</h4>
                <p><strong>Problem:</strong> Distinguishing between similar objects</p>
                <p><strong>Example:</strong> Ball vs. egg, cat vs. dog</p>
                <p><strong>Solution:</strong> Fine-grained feature analysis</p>
            </div>
            <div class="challenge-item">
                <h4>üìè Size &amp; Distance Variations</h4>
                <p><strong>Problem:</strong> Objects appear smaller when farther away</p>
                <p><strong>Example:</strong> Same car looks different at various distances</p>
                <p><strong>Solution:</strong> Scale-invariant features</p>
            </div>
            <div class="challenge-item">
                <h4>üîÑ Rotation Handling</h4>
                <p><strong>Problem:</strong> Same object from different angles</p>
                <p><strong>Example:</strong> Chair viewed from front vs. side</p>
                <p><strong>Solution:</strong> Rotation-invariant descriptors</p>
            </div>
            <div class="challenge-item">
                <h4>ü´• Occlusion Problems</h4>
                <p><strong>Problem:</strong> Partially hidden or overlapped objects</p>
                <p><strong>Example:</strong> Person behind a tree</p>
                <p><strong>Solution:</strong> Robust feature matching</p>
            </div>
            <div class="challenge-item">
                <h4>üé≠ Viewpoint Changes</h4>
                <p><strong>Problem:</strong> Objects look different from various viewpoints</p>
                <p><strong>Example:</strong> Building from ground vs. aerial view</p>
                <p><strong>Solution:</strong> Multi-view geometry</p>
            </div>
        </div>

        <div class="section-divider"></div>

        <h2>üî≤ IMAGE REPRESENTATION AS PIXELS</h2>

        <div class="exam-focus">
            <h4>üí° EXAM TIP: Understand Digital Image Basics</h4>
            <p>Know how images are stored as numerical arrays and the difference between grayscale and RGB!</p>
        </div>

        <h3>üì± How Computers "See" Images</h3>

        <div class="pixel-demo">
            <h4>üñºÔ∏è Digital Image = Matrix of Numbers</h4>
            <p>Every image is just a 2D array (matrix) where each element represents a pixel's intensity or color</p>
        </div>

        <h3>üé® Color Spaces</h3>

        <div class="comparison">
            <div class="vs-left">
                <h4>‚ö´ GRAYSCALE IMAGES</h4>
                <ul>
                    <li><strong>Format:</strong> Single 2D matrix</li>
                    <li><strong>Values:</strong> 0 (black) to 255 (white)</li>
                    <li><strong>Storage:</strong> 1 byte per pixel</li>
                    <li><strong>Use case:</strong> Medical imaging, text recognition</li>
                    <li><strong>Example:</strong> X-rays, document scanning</li>
                </ul>
            </div>
            <div class="vs-right">
                <h4>üåà RGB COLOR IMAGES</h4>
                <ul>
                    <li><strong>Format:</strong> Three 2D matrices (Red, Green, Blue)</li>
                    <li><strong>Values:</strong> 0-255 for each color channel</li>
                    <li><strong>Storage:</strong> 3 bytes per pixel</li>
                    <li><strong>Use case:</strong> Photography, web images, displays</li>
                    <li><strong>Example:</strong> Digital photos, websites</li>
                </ul>
            </div>
        </div>

        <h3>üî¢ Pixel Representation Example</h3>

        <div class="matrix-demo">
            <h4>Grayscale 3x3 Image</h4>
            <p>
                [100, 150, 200]<br>
                [50, 255, 180]<br>
                [30, 80, 120]
            </p>
            <p><strong>Interpretation:</strong> 255 = bright white pixel, 30 = dark pixel</p>
        </div>

        <div class="matrix-demo">
            <h4>RGB 2x2 Image (showing Red channel only)</h4>
            <p>
                Red: [255, 100] Green: [50, 200] Blue: [0, 150]<br>
                Red: [180, 60] Green: [90, 255] Blue: [120, 30]
            </p>
            <p><strong>Result:</strong> Top-left pixel = (255,50,0) = bright red</p>
        </div>

        <div class="analogy">
            <p><span class="emoji">üß©</span><strong>Think of it like:</strong> A digital image is like a giant mosaic
                made of tiny colored squares (pixels), where each square has a specific color code!</p>
        </div>

        <div class="section-divider"></div>

        <h2>üîß IMAGE FILTERS &amp; CONVOLUTION</h2>

        <div class="critical-exam">
            <h4>üî• HIGH-PROBABILITY EXAM TOPIC</h4>
            <p>2D Convolution and filters are fundamental! Understand how kernels work and their applications.</p>
        </div>

        <h3>üéõÔ∏è What Are Image Filters?</h3>

        <div class="step-box">
            <p><strong>Definition:</strong> A filter is a function that takes an image as input, applies modifications,
                and returns a filtered image</p>
            <p><strong>Purpose:</strong> Extract useful information, enhance images, or detect specific features</p>
            <p><strong>Applications:</strong> Smoothing, edge detection, corner detection, noise reduction</p>
        </div>

        <h3>üîÑ 2D Convolution Process</h3>

        <div class="filter-demo">
            <h4>üìê How 2D Convolution Works</h4>
            <p><strong>Step 1:</strong> Take a small matrix (kernel/filter) - usually 3x3 or 5x5</p>
            <p><strong>Step 2:</strong> Slide this kernel over the image pixel by pixel</p>
            <p><strong>Step 3:</strong> Multiply corresponding values and sum the results</p>
            <p><strong>Step 4:</strong> Place the result in the output image</p>
        </div>

        <h3>üéØ Common Filter Types</h3>

        <table>
            <tbody>
                <tr>
                    <th>Filter Type</th>
                    <th>Purpose</th>
                    <th>Kernel Example</th>
                    <th>Effect</th>
                </tr>
                <tr>
                    <td><strong>Smoothing (Blur)</strong></td>
                    <td>Reduce noise, soften image</td>
                    <td>All positive values (e.g., 1/9 for each cell in 3x3)</td>
                    <td>Blurred, less detailed image</td>
                </tr>
                <tr>
                    <td><strong>Edge Detection</strong></td>
                    <td>Find boundaries between objects</td>
                    <td>Sobel, Prewitt kernels (mix of + and - values)</td>
                    <td>Highlights edges, darkens uniform areas</td>
                </tr>
                <tr>
                    <td><strong>Sharpening</strong></td>
                    <td>Enhance details and edges</td>
                    <td>Center positive, surrounding negative</td>
                    <td>More defined edges and details</td>
                </tr>
                <tr>
                    <td><strong>Emboss</strong></td>
                    <td>Create 3D-like effect</td>
                    <td>Asymmetric positive/negative pattern</td>
                    <td>Raised/carved appearance</td>
                </tr>
            </tbody>
        </table>

        <h3>üìä Convolution Example</h3>

        <div class="kernel-visual">
            <h4>3x3 Edge Detection Kernel (Sobel X)</h4>
            <div class="matrix-demo">
                [-1, 0, +1]<br>
                [-2, 0, +2]<br>
                [-1, 0, +1]
            </div>
            <p><strong>Effect:</strong> Detects vertical edges (left-right intensity changes)</p>
            <p><strong>How:</strong> Negative values on left, positive on right = highlights vertical transitions</p>
        </div>

        <div class="section-divider"></div>

        <h2>üåü FEATURE DETECTION</h2>

        <div class="exam-focus">
            <h4>üéØ EXAM ESSENTIAL: Feature Detection Pipeline</h4>
            <p>Understand the three steps: Detection ‚Üí Description ‚Üí Matching</p>
        </div>

        <h3>üîç What Are Features?</h3>

        <div class="step-box">
            <p><strong>Definition:</strong> Features are points of interest in an image that contain important
                information for solving a specific problem</p>
            <p><strong>Components:</strong></p>
            <ul>
                <li><strong>Keypoint:</strong> The coordinates (x, y) where the feature is located</li>
                <li><strong>Descriptor:</strong> A vector containing semantic information about the feature</li>
            </ul>
        </div>

        <h3>üìù Three-Step Feature Detection Process</h3>

        <table>
            <tbody>
                <tr>
                    <th>Step</th>
                    <th>Purpose</th>
                    <th>Output</th>
                    <th>Example</th>
                </tr>
                <tr>
                    <td><strong>1. Detection</strong></td>
                    <td>Find interesting points in the image</td>
                    <td>Keypoint coordinates (x, y)</td>
                    <td>Corner at pixel (150, 200)</td>
                </tr>
                <tr>
                    <td><strong>2. Description</strong></td>
                    <td>Extract information about each feature</td>
                    <td>Feature descriptor vector</td>
                    <td>[0.2, 0.8, 0.1, 0.5, ...] (128 dimensions)</td>
                </tr>
                <tr>
                    <td><strong>3. Matching</strong></td>
                    <td>Find corresponding features between images</td>
                    <td>Feature correspondences</td>
                    <td>Feature A in image 1 = Feature B in image 2</td>
                </tr>
            </tbody>
        </table>

        <h3>üéØ Types of Features</h3>

        <div class="feature-type">
            <h4>üìç CORNERS</h4>
            <ul>
                <li><strong>What:</strong> Points where two edges meet</li>
                <li><strong>Why important:</strong> Stable, distinctive, easy to locate precisely</li>
                <li><strong>Detection method:</strong> Harris corner detector, FAST</li>
                <li><strong>Example:</strong> Building corners, object boundaries</li>
            </ul>
        </div>

        <div class="feature-type">
            <h4>üìè EDGES</h4>
            <ul>
                <li><strong>What:</strong> Boundaries between different regions</li>
                <li><strong>Why important:</strong> Define object shapes and structure</li>
                <li><strong>Detection method:</strong> Sobel, Canny edge detection</li>
                <li><strong>Example:</strong> Object outlines, horizon lines</li>
            </ul>
        </div>

        <div class="feature-type">
            <h4>üü° BLOBS</h4>
            <ul>
                <li><strong>What:</strong> Regions that differ in brightness or color</li>
                <li><strong>Why important:</strong> Represent object parts or entire small objects</li>
                <li><strong>Detection method:</strong> Difference of Gaussians (DoG), SIFT</li>
                <li><strong>Example:</strong> Eyes in faces, spots on animals</li>
            </ul>
        </div>

        <h3>‚ö° Six Characteristics of Good Feature Detection</h3>

        <table>
            <tbody>
                <tr>
                    <th>Characteristic</th>
                    <th>Description</th>
                    <th>Why Important</th>
                </tr>
                <tr>
                    <td><strong>Robustness</strong></td>
                    <td>Reliable detection under difficult conditions (lighting, noise, rotation)</td>
                    <td>Works in real-world scenarios</td>
                </tr>
                <tr>
                    <td><strong>Repeatability</strong></td>
                    <td>Same features detected regardless of viewpoint or angle</td>
                    <td>Consistent results across different images</td>
                </tr>
                <tr>
                    <td><strong>Accuracy</strong></td>
                    <td>Precise localization of features at pixel level</td>
                    <td>Enables accurate measurements and matching</td>
                </tr>
                <tr>
                    <td><strong>Generality</strong></td>
                    <td>Applicable to different use cases without modification</td>
                    <td>Versatile across various applications</td>
                </tr>
                <tr>
                    <td><strong>Efficiency</strong></td>
                    <td>Low computational cost for real-time processing</td>
                    <td>Practical for mobile and embedded systems</td>
                </tr>
                <tr>
                    <td><strong>Quantity</strong></td>
                    <td>Detect enough features to create meaningful representation</td>
                    <td>Sufficient information for recognition tasks</td>
                </tr>
            </tbody>
        </table>

        <div class="section-divider"></div>

        <h2>üìê CAMERA CALIBRATION &amp; DISTORTION</h2>

        <div class="critical-exam">
            <h4>üî• EXAM RELEVANT: Calibration Concepts</h4>
            <p>Know the difference between intrinsic and extrinsic parameters!</p>
        </div>

        <h3>üéØ What Is Camera Calibration?</h3>

        <div class="calibration-box">
            <p><strong>Purpose:</strong> Estimate camera parameters to remove distortion and enable accurate
                measurements</p>
            <p><strong>Goal:</strong> Extract 3D information from 2D images</p>
            <p><strong>Benefit:</strong> Measure real-world distances and sizes in units like meters</p>
        </div>

        <h3>üìä Camera Parameters</h3>

        <div class="comparison">
            <div class="vs-left">
                <h4>üåç EXTRINSIC PARAMETERS</h4>
                <ul>
                    <li><strong>What:</strong> Camera's position and orientation in the world</li>
                    <li><strong>Includes:</strong></li>
                    <li>- Position coordinates (x, y, z)</li>
                    <li>- Rotation angles (roll, pitch, yaw)</li>
                    <li><strong>Use:</strong> Where the camera is looking</li>
                    <li><strong>Example:</strong> Security camera pointing at building entrance</li>
                </ul>
            </div>
            <div class="vs-right">
                <h4>üîç INTRINSIC PARAMETERS</h4>
                <ul>
                    <li><strong>What:</strong> Camera's internal characteristics</li>
                    <li><strong>Includes:</strong></li>
                    <li>- Focal length</li>
                    <li>- Optical center</li>
                    <li>- Lens distortion parameters</li>
                    <li><strong>Use:</strong> How the camera "sees"</li>
                    <li><strong>Example:</strong> Smartphone vs. DSLR have different focal lengths</li>
                </ul>
            </div>
        </div>

        <h3>üîß Types of Lens Distortion</h3>

        <table>
            <tbody>
                <tr>
                    <th>Distortion Type</th>
                    <th>Effect</th>
                    <th>Appearance</th>
                    <th>Common In</th>
                </tr>
                <tr>
                    <td><strong>Barrel Distortion</strong></td>
                    <td>Straight lines appear curved outward</td>
                    <td>Image looks "puffed out" like a barrel</td>
                    <td>Wide-angle lenses, fish-eye lenses</td>
                </tr>
                <tr>
                    <td><strong>Pincushion Distortion</strong></td>
                    <td>Straight lines appear curved inward</td>
                    <td>Image looks "pinched" at the center</td>
                    <td>Telephoto lenses, zoom lenses</td>
                </tr>
                <tr>
                    <td><strong>Tangential Distortion</strong></td>
                    <td>Image appears tilted or skewed</td>
                    <td>Rectangular objects look like parallelograms</td>
                    <td>Manufacturing defects, misaligned sensors</td>
                </tr>
            </tbody>
        </table>

        <div class="analogy">
            <p><span class="emoji">üì∑</span><strong>Real-World Example:</strong> Ever noticed how straight buildings
                look curved in wide-angle photos? That's barrel distortion! Calibration can fix this digitally.</p>
        </div>

        <div class="section-divider"></div>

        <h2>üîó SEMANTIC SEGMENTATION</h2>

        <div class="exam-focus">
            <h4>üí° ADVANCED TOPIC: Pixel-Level Classification</h4>
            <p>Understand how semantic segmentation assigns a category to every pixel in an image.</p>
        </div>

        <h3>üéØ What Is Semantic Segmentation?</h3>

        <div class="step-box">
            <p><strong>Definition:</strong> Pixel-level classification where each pixel is assigned to an object
                category</p>
            <p><strong>Input:</strong> Image with one or more objects</p>
            <p><strong>Output:</strong> Image where each pixel is labeled by category</p>
            <p><strong>Example:</strong> Every pixel labeled as "background," "chair," or "coffee table"</p>
        </div>

        <h3>üìä Segmentation vs Other CV Tasks</h3>

        <table>
            <tbody>
                <tr>
                    <th>Task</th>
                    <th>Output</th>
                    <th>Granularity</th>
                    <th>Example</th>
                </tr>
                <tr>
                    <td><strong>Classification</strong></td>
                    <td>Single label for entire image</td>
                    <td>Image-level</td>
                    <td>"This image contains a cat"</td>
                </tr>
                <tr>
                    <td><strong>Object Detection</strong></td>
                    <td>Bounding boxes around objects</td>
                    <td>Object-level</td>
                    <td>Rectangle around each cat</td>
                </tr>
                <tr>
                    <td><strong>Semantic Segmentation</strong></td>
                    <td>Category for each pixel</td>
                    <td>Pixel-level</td>
                    <td>Every pixel labeled as "cat," "background," etc.</td>
                </tr>
                <tr>
                    <td><strong>Instance Segmentation</strong></td>
                    <td>Individual object masks</td>
                    <td>Instance-level</td>
                    <td>Separate masks for "cat1," "cat2," "background"</td>
                </tr>
            </tbody>
        </table>

        <div class="section-divider"></div>

        <h2>üîó CONNECTIONS TO PREVIOUS UNITS</h2>

        <div class="key-points">
            <h4>üåâ Building Bridges: How Computer Vision Connects</h4>
            <ul>
                <li><span class="emoji">üîó</span><strong>Unit 1 - Neural Networks:</strong> Modern CV uses CNNs
                    (Convolutional Neural Networks)</li>
                <li><span class="emoji">üîó</span><strong>Unit 1 - Feature Learning:</strong> Deep learning automatically
                    learns visual features</li>
                <li><span class="emoji">üîó</span><strong>Unit 2 - NLP Applications:</strong> CV complements NLP in
                    multimodal AI systems</li>
                <li><span class="emoji">üîó</span><strong>Unit 2 - Business Applications:</strong> CV powers autonomous
                    vehicles, medical imaging, retail</li>
                <li><span class="emoji">üîó</span><strong>Unit 3 - Reinforcement Learning:</strong> RL agents use CV for
                    environmental perception</li>
                <li><span class="emoji">üîó</span><strong>Mathematical Foundations:</strong> Convolution, matrix
                    operations from linear algebra</li>
            </ul>
        </div>

        <div class="section-divider"></div>

        <h2>üöó REAL-WORLD APPLICATIONS</h2>

        <table>
            <tbody>
                <tr>
                    <th>Application</th>
                    <th>CV Techniques Used</th>
                    <th>Key Challenges</th>
                    <th>Impact</th>
                </tr>
                <tr>
                    <td><strong>Autonomous Vehicles</strong></td>
                    <td>Object detection, semantic segmentation, depth estimation</td>
                    <td>Real-time processing, varying weather, safety-critical</td>
                    <td>Transportation revolution, reduced accidents</td>
                </tr>
                <tr>
                    <td><strong>Medical Imaging</strong></td>
                    <td>Image enhancement, feature detection, classification</td>
                    <td>High accuracy required, regulatory approval</td>
                    <td>Early disease detection, surgical planning</td>
                </tr>
                <tr>
                    <td><strong>Quality Control</strong></td>
                    <td>Defect detection, measurement, classification</td>
                    <td>Industrial environments, speed requirements</td>
                    <td>Improved product quality, reduced waste</td>
                </tr>
                <tr>
                    <td><strong>Retail &amp; E-commerce</strong></td>
                    <td>Product recognition, visual search, AR try-on</td>
                    <td>Diverse products, user experience</td>
                    <td>Enhanced shopping, inventory management</td>
                </tr>
                <tr>
                    <td><strong>Security &amp; Surveillance</strong></td>
                    <td>Face recognition, behavior analysis, tracking</td>
                    <td>Privacy concerns, false positives</td>
                    <td>Enhanced security, crime prevention</td>
                </tr>
            </tbody>
        </table>

    </div>
</body>

</html>